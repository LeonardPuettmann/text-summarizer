 This blog post will share our experience with fine-tuning sentence embeddings on a commonly available dataset using similarity learning . We additionally explore how this could benefit the labeling workflow in Kern refinery .  Quaterion is able to use different kinds of similarity information in order to fine-tune the embeddings . The goal is to learn a mapping from one embedding to another . For that we are going to use a pre-trained LLM as the encoder and add  The training details are covered by Quaterion for us, which uses PyTorch Lightning under the hood . The optimizer (we chose Adam) is specified in the model itself, we just need to call the fit method . The test data consists of the 9. 156 (al  Quaterion's neighbor-based similarity improved w. r. t. classification but this linear classification model did not find it easier to separate the classes from one another . We are working on methods to fine-tune embeddings leading to a better separation of classes in the 2